#!/usr/bin/env node
"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const PerformanceBenchmarkRunner_1 = require("../performance/PerformanceBenchmarkRunner");
const AnalysisConfigManager_1 = require("../config/AnalysisConfigManager");
const path_1 = require("path");
const fs_1 = require("fs");
/**
 * Parse command line arguments
 */
function parseArgs() {
    const args = process.argv.slice(2);
    const options = {};
    for (let i = 0; i < args.length; i++) {
        const arg = args[i];
        switch (arg) {
            case '--config':
            case '-c':
                options.config = args[++i];
                break;
            case '--iterations':
            case '-i':
                options.iterations = parseInt(args[++i], 10);
                break;
            case '--warmup':
            case '-w':
                options.warmup = parseInt(args[++i], 10);
                break;
            case '--output':
            case '-o':
                options.output = args[++i];
                break;
            case '--baseline':
            case '-b':
                options.baseline = args[++i];
                break;
            case '--verbose':
            case '-v':
                options.verbose = true;
                break;
            case '--help':
            case '-h':
                options.help = true;
                break;
            case '--quick':
            case '-q':
                options.quick = true;
                break;
            case '--stress':
            case '-s':
                options.stress = true;
                break;
            case '--compare':
                options.compare = true;
                break;
            default:
                if (arg.startsWith('-')) {
                    console.warn(`Unknown option: ${arg}`);
                }
                break;
        }
    }
    return options;
}
/**
 * Display help information
 */
function showHelp() {
    console.log(`
üöÄ Release Analysis Performance Benchmark Tool

USAGE:
  npm run benchmark:performance [OPTIONS]

OPTIONS:
  -c, --config <file>     Analysis configuration file (default: auto-detect)
  -i, --iterations <n>    Number of benchmark iterations (default: 5)
  -w, --warmup <n>        Number of warmup iterations (default: 2)
  -o, --output <dir>      Output directory for results (default: ./benchmark-results)
  -b, --baseline <file>   Baseline file for regression comparison
  -v, --verbose           Enable detailed logging
  -q, --quick             Run quick benchmark suite (fewer tests)
  -s, --stress            Run stress test suite (more intensive)
      --compare           Compare with previous baseline
  -h, --help              Show this help message

EXAMPLES:
  # Run standard benchmark suite
  npm run benchmark:performance

  # Run with custom configuration
  npm run benchmark:performance -- --config ./my-config.json --verbose

  # Run quick benchmark with 10 iterations
  npm run benchmark:performance -- --quick --iterations 10

  # Run stress test and save to custom directory
  npm run benchmark:performance -- --stress --output ./stress-results

  # Compare with baseline
  npm run benchmark:performance -- --compare --baseline ./baseline.json

BENCHMARK SUITES:
  Standard: Comprehensive performance testing across different repository sizes
  Quick:    Reduced test set for faster feedback during development
  Stress:   Intensive testing with large datasets and high concurrency

PERFORMANCE TARGETS:
  - Analysis Time: <30s for repositories with <100 documents
  - Memory Usage: <512MB peak memory consumption
  - Throughput:   >3 documents/second processing rate
  - Regression:   <10% performance degradation from baseline

OUTPUT:
  Results are saved in JSON format with detailed metrics including:
  - Execution times (mean, median, percentiles)
  - Memory usage patterns (initial, peak, final)
  - Throughput measurements (docs/sec, bytes/sec)
  - Cache efficiency statistics
  - Parallel processing efficiency
  - Regression analysis (if baseline provided)
`);
}
/**
 * Validate CLI options
 */
function validateOptions(options) {
    const errors = [];
    if (options.iterations !== undefined && (options.iterations < 1 || options.iterations > 100)) {
        errors.push('Iterations must be between 1 and 100');
    }
    if (options.warmup !== undefined && (options.warmup < 0 || options.warmup > 20)) {
        errors.push('Warmup iterations must be between 0 and 20');
    }
    if (options.config && !(0, fs_1.existsSync)(options.config)) {
        errors.push(`Configuration file not found: ${options.config}`);
    }
    if (options.baseline && !(0, fs_1.existsSync)(options.baseline)) {
        errors.push(`Baseline file not found: ${options.baseline}`);
    }
    return errors;
}
/**
 * Load analysis configuration
 */
async function loadAnalysisConfig(configPath) {
    const configManager = AnalysisConfigManager_1.AnalysisConfigManager.getInstance();
    if (configPath) {
        const result = await configManager.loadConfig(configPath);
        return result.config;
    }
    // Try to auto-detect configuration
    const possiblePaths = [
        '.kiro/release-analysis-config.json',
        'release-analysis-config.json',
        '.kiro/config/analysis.json'
    ];
    for (const path of possiblePaths) {
        if ((0, fs_1.existsSync)(path)) {
            console.log(`üìã Using configuration: ${path}`);
            const result = await configManager.loadConfig(path);
            return result.config;
        }
    }
    // Use default configuration
    console.log('üìã Using default configuration');
    return await configManager.getConfig();
}
/**
 * Create benchmark suite configuration based on CLI options
 */
function createBenchmarkConfig(options) {
    const workingDir = process.cwd();
    let config = {
        outputDir: options.output || (0, path_1.join)(workingDir, 'benchmark-results'),
        iterations: options.iterations || 5,
        warmupIterations: options.warmup || 2,
        enableDetailedLogging: options.verbose || false,
        saveResults: true,
        compareWithBaseline: options.compare || false,
        baselineFile: options.baseline
    };
    // Adjust for quick mode
    if (options.quick) {
        config.iterations = Math.min(config.iterations, 3);
        config.warmupIterations = Math.min(config.warmupIterations, 1);
    }
    // Adjust for stress mode
    if (options.stress) {
        config.iterations = Math.max(config.iterations, 10);
        config.warmupIterations = Math.max(config.warmupIterations, 3);
    }
    return config;
}
/**
 * Format benchmark results for console output
 */
function formatResults(results) {
    console.log('\nüìä PERFORMANCE BENCHMARK RESULTS');
    console.log('='.repeat(60));
    console.log(`üïê Execution Time: ${new Date(results.timestamp).toLocaleString()}`);
    console.log(`üñ•Ô∏è  Environment: ${results.environment.platform} ${results.environment.arch}`);
    console.log(`üíª Node.js: ${results.environment.nodeVersion}`);
    console.log(`üß† CPU Cores: ${results.environment.cpuCount}`);
    console.log(`üíæ Total Memory: ${(results.environment.totalMemory / 1024 / 1024 / 1024).toFixed(1)}GB`);
    console.log('\nüìà TEST RESULTS:');
    console.log('-'.repeat(60));
    for (const result of results.results) {
        const { config, metrics, statistics } = result;
        console.log(`\nüß™ ${config.name.toUpperCase()}`);
        console.log(`   Description: ${config.description}`);
        console.log(`   Documents: ${config.documentCount} (${(config.documentSize / 1024).toFixed(1)}KB each)`);
        console.log(`   Concurrency: ${config.concurrency}`);
        console.log(`   Optimizations: ${config.enableOptimizations ? 'Enabled' : 'Disabled'}`);
        console.log(`   Results:`);
        console.log(`     ‚è±Ô∏è  Mean Time: ${statistics.mean.toFixed(1)}ms`);
        console.log(`     üìä Median Time: ${statistics.median.toFixed(1)}ms`);
        console.log(`     üìà 95th Percentile: ${statistics.percentile95.toFixed(1)}ms`);
        console.log(`     üéØ Std Deviation: ${statistics.standardDeviation.toFixed(1)}ms`);
        console.log(`     üöÄ Throughput: ${metrics.throughput.documentsPerSecond.toFixed(1)} docs/sec`);
        console.log(`     üíæ Peak Memory: ${(metrics.memoryUsage.peak / 1024 / 1024).toFixed(1)}MB`);
        console.log(`     üìä Cache Hit Rate: ${(metrics.cacheStats.hitRate * 100).toFixed(1)}%`);
        console.log(`     ‚ö° Parallel Efficiency: ${(metrics.parallelStats.efficiency * 100).toFixed(1)}%`);
        // Performance assessment
        const isGood = statistics.mean < 30000 && // < 30s
            metrics.memoryUsage.peak < 512 * 1024 * 1024 && // < 512MB
            metrics.throughput.documentsPerSecond > 3; // > 3 docs/sec
        console.log(`     ${isGood ? '‚úÖ' : '‚ö†Ô∏è'} Performance: ${isGood ? 'GOOD' : 'NEEDS ATTENTION'}`);
    }
    console.log('\nüìã SUMMARY:');
    console.log('-'.repeat(60));
    console.log(`‚úÖ Passed Tests: ${results.summary.passedTests}/${results.summary.totalTests}`);
    console.log(`‚ùå Failed Tests: ${results.summary.failedTests}`);
    console.log(`‚è±Ô∏è  Total Execution Time: ${(results.summary.totalExecutionTime / 1000).toFixed(1)}s`);
    console.log(`üìà Average Performance: ${results.summary.averagePerformance.toFixed(1)}ms`);
    if (results.summary.regressions.length > 0) {
        console.log(`\n‚ö†Ô∏è  PERFORMANCE REGRESSIONS:`);
        for (const regression of results.summary.regressions) {
            console.log(`   - ${regression.testName}: +${regression.regressionPercent.toFixed(1)}%`);
        }
    }
    else if (results.config.compareWithBaseline) {
        console.log(`\n‚úÖ No performance regressions detected`);
    }
    console.log(`\nüíæ Results saved to: ${results.config.outputDir}`);
    console.log('='.repeat(60));
}
/**
 * Main execution function
 */
async function main() {
    const options = parseArgs();
    if (options.help) {
        showHelp();
        process.exit(0);
    }
    // Validate options
    const validationErrors = validateOptions(options);
    if (validationErrors.length > 0) {
        console.error('‚ùå Validation errors:');
        for (const error of validationErrors) {
            console.error(`   - ${error}`);
        }
        process.exit(1);
    }
    try {
        console.log('üöÄ Starting Release Analysis Performance Benchmarks');
        console.log(`üìÅ Working Directory: ${process.cwd()}`);
        // Load configuration
        const analysisConfig = await loadAnalysisConfig(options.config);
        // Create benchmark configuration
        const benchmarkConfig = createBenchmarkConfig(options);
        if (options.verbose) {
            console.log('üìã Benchmark Configuration:');
            console.log(`   Iterations: ${benchmarkConfig.iterations}`);
            console.log(`   Warmup: ${benchmarkConfig.warmupIterations}`);
            console.log(`   Output: ${benchmarkConfig.outputDir}`);
            console.log(`   Compare with baseline: ${benchmarkConfig.compareWithBaseline}`);
            if (benchmarkConfig.baselineFile) {
                console.log(`   Baseline file: ${benchmarkConfig.baselineFile}`);
            }
        }
        // Initialize and run benchmark runner
        const runner = new PerformanceBenchmarkRunner_1.PerformanceBenchmarkRunner(process.cwd(), analysisConfig, benchmarkConfig);
        const startTime = Date.now();
        const results = await runner.runBenchmarkSuite();
        const totalTime = Date.now() - startTime;
        // Display results
        formatResults(results);
        // Exit with appropriate code
        const hasFailures = results.summary.failedTests > 0;
        const hasRegressions = results.summary.regressions.length > 0;
        if (hasFailures || hasRegressions) {
            console.log(`\n‚ùå Benchmark completed with issues (${totalTime}ms)`);
            process.exit(1);
        }
        else {
            console.log(`\n‚úÖ Benchmark completed successfully (${totalTime}ms)`);
            process.exit(0);
        }
    }
    catch (error) {
        console.error(`\n‚ùå Benchmark failed: ${error instanceof Error ? error.message : String(error)}`);
        if (options.verbose && error instanceof Error && error.stack) {
            console.error('\nStack trace:');
            console.error(error.stack);
        }
        process.exit(1);
    }
}
// Handle unhandled promise rejections
process.on('unhandledRejection', (reason, promise) => {
    console.error('Unhandled Rejection at:', promise, 'reason:', reason);
    process.exit(1);
});
// Handle uncaught exceptions
process.on('uncaughtException', (error) => {
    console.error('Uncaught Exception:', error);
    process.exit(1);
});
// Run the CLI
if (require.main === module) {
    main();
}
//# sourceMappingURL=performance-benchmark.js.map